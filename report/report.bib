@article{Demsar2016BalancedMixture,
    title   = {{A Balanced Mixture of Antagonistic Pressures Promotes the Evolution of Parallel Movement}},
    year    = {2016},
    journal = {Scientific Reports},
    author  = {Dem{\v{s}}ar, Jure and {\v{S}}trumbelj, Erik and Lebar Bajec, Iztok},
    volume  = {6},
    doi     = {10.1038/srep39428}
}

@article{Demsar2017LinguisticEvolution,
    title   = {{Evolution of Collective Behaviour in an Artificial World Using Linguistic Fuzzy Rule-Based Systems}},
    year    = {2017},
    journal = {PLoS ONE},
    author  = {Dem{\v{s}}ar, Jure and Lebar Bajec, Iztok},
    number  = {1},
    pages   = {1--20},
    volume  = {12},
    doi     = {10.1371/journal.pone.0168876}
}

@inproceedings{federmann-etal-2019-multilingual,
    title     = {Multilingual Whispers: Generating Paraphrases with Translation},
    author    = {Federmann, Christian  and
                 Elachqar, Oussama  and
                 Quirk, Chris},
    booktitle = {Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)},
    month     = nov,
    year      = {2019},
    address   = {Hong Kong, China},
    publisher = {Association for Computational Linguistics},
    url       = {https://aclanthology.org/D19-5503},
    doi       = {10.18653/v1/D19-5503},
    pages     = {17--26},
    abstract  = {Naturally occurring paraphrase data, such as multiple news stories about the same event, is a useful but rare resource. This paper compares translation-based paraphrase gathering using human, automatic, or hybrid techniques to monolingual paraphrasing by experts and non-experts. We gather translations, paraphrases, and empirical human quality assessments of these approaches. Neural machine translation techniques, especially when pivoting through related languages, provide a relatively robust source of paraphrases with diversity comparable to expert human paraphrases. Surprisingly, human translators do not reliably outperform neural systems. The resulting data release will not only be a useful test set, but will also allow additional explorations in translation and paraphrase quality assessments and relationships.}
}

@misc{evaluation-metrics-in-paraphrase-generation,
    doi       = {10.48550/ARXIV.2202.08479},
    url       = {https://arxiv.org/abs/2202.08479},
    author    = {Shen, Lingfeng and Liu, Lemao and Jiang, Haiyun and Shi, Shuming},
    keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title     = {On the Evaluation Metrics for Paraphrase Generation},
    publisher = {arXiv},
    year      = {2022},
    copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{zhou-bhat-2021-paraphrase,
    title     = {Paraphrase Generation: A Survey of the State of the Art},
    author    = {Zhou, Jianing  and
                 Bhat, Suma},
    booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
    month     = nov,
    year      = {2021},
    address   = {Online and Punta Cana, Dominican Republic},
    publisher = {Association for Computational Linguistics},
    url       = {https://aclanthology.org/2021.emnlp-main.414},
    doi       = {10.18653/v1/2021.emnlp-main.414},
    pages     = {5075--5086},
    abstract  = {This paper focuses on paraphrase generation,which is a widely studied natural language generation task in NLP. With the development of neural models, paraphrase generation research has exhibited a gradual shift to neural methods in the recent years. This has provided architectures for contextualized representation of an input text and generating fluent, diverseand human-like paraphrases. This paper surveys various approaches to paraphrase generation with a main focus on neural methods.}
}

 @misc{11356/1694,
    title     = {Slovenian datasets for contextual synonym and antonym detection},
    author    = {Pegan, Jasmina and Robnik-{\v S}ikonja, Marko and Kosem, Iztok and Gantar, Polona and Ponikvar, Primo{\v z} and Laskowski, Cyprian},
    url       = {http://hdl.handle.net/11356/1694},
    note      = {Slovenian language resource repository {CLARIN}.{SI}},
    copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},
    issn      = {2820-4042},
    year      = {2022}
}

 @article{DBLP:journals/corr/abs-1908-11828,
    author     = {Yinfei Yang and
                  Yuan Zhang and
                  Chris Tar and
                  Jason Baldridge},
    title      = {{PAWS-X:} {A} Cross-lingual Adversarial Dataset for Paraphrase Identification},
    journal    = {CoRR},
    volume     = {abs/1908.11828},
    year       = {2019},
    url        = {http://arxiv.org/abs/1908.11828},
    eprinttype = {arXiv},
    eprint     = {1908.11828},
    timestamp  = {Wed, 04 Sep 2019 15:47:27 +0200},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1908-11828.bib},
    bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2010-12885,
    author     = {Tong Niu and
                  Semih Yavuz and
                  Yingbo Zhou and
                  Huan Wang and
                  Nitish Shirish Keskar and
                  Caiming Xiong},
    title      = {Unsupervised Paraphrase Generation via Dynamic Blocking},
    journal    = {CoRR},
    volume     = {abs/2010.12885},
    year       = {2020},
    url        = {https://arxiv.org/abs/2010.12885},
    eprinttype = {arXiv},
    eprint     = {2010.12885},
    timestamp  = {Mon, 02 Nov 2020 18:17:09 +0100},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2010-12885.bib},
    bibsource  = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{ulcar-robnik2020finest,
    author    = {Ulčar, M. and Robnik-Šikonja, M.},
    year      = 2020,
    title     = {{FinEst BERT} and {CroSloEngual BERT}: less is more in multilingual models},
    editor    = {Sojka, P and Kopeček, I and Pala, K and Horák, A},
    booktitle = {Text, Speech, and Dialogue {TSD 2020}},
    series    = {Lecture Notes in Computer Science},
    volume    = 12284,
    publisher = {Springer},
    url       = {https://doi.org/10.1007/978-3-030-58323-1_11}
}
 @misc{11356/1747,
    title     = {Training corpus {SUK} 1.0},
    author    = {Arhar Holdt, {\v S}pela and Krek, Simon and Dobrovoljc, Kaja and Erjavec, Toma{\v z} and Gantar, Polona and {\v C}ibej, Jaka and Pori, Eva and Ter{\v c}on, Luka and Munda, Tina and {\v Z}itnik, Slavko and Robida, Nejc and Blagus, Neli and Mo{\v z}e, Sara and Ledinek, Nina and Holz, Nanika and Zupan, Katja and Kuzman, Taja and Kav{\v c}i{\v c}, Teja and {\v S}krjanec, Iza and Marko, Dafne and Jezer{\v s}ek, Lucija and Zajc, Anja},
    url       = {http://hdl.handle.net/11356/1747},
    note      = {Slovenian language resource repository {CLARIN}.{SI}},
    copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},
    issn      = {2820-4042},
    year      = {2022}
}